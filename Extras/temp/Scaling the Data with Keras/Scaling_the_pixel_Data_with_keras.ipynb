{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845d5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.typing\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c811a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (60000, 28, 28) (60000,)\n",
      "Test (10000, 28, 28) (10000,)\n",
      "Train 0 255 33.318421449829934\n",
      "Test 0 255 33.791224489795916 79.17246322228644\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "print(f\"Train {train_images.shape} {train_labels.shape}\")\n",
    "print(f\"Test {test_images.shape} {test_labels.shape}\")\n",
    "print(f\"Train {train_images.min()} {train_images.max()} {train_images.mean()}\")\n",
    "print(f\"Test {test_images.min()} {test_images.max()} {test_images.mean()} {test_images.std()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf7fc34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train => min: 0.000, max: 255.000\n",
      "Test => min: 0.000. max: 255.000\n",
      "Batch Sizes: train => 938, test => 157\n",
      "Batch size: (64, 28, 28, 1) - min => 0.000, max => 1.000\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the pixel values using DataGenerator\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "# Reshaping the image to fit the single channel\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "\n",
    "print(\"Train => min: %.3f, max: %.3f\" % (trainX.min(), trainX.max()))\n",
    "print(\"Test => min: %.3f. max: %.3f\" % (testX.min(), testX.max()))\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1.0 / 255.0)\n",
    "\n",
    "# creating the iterators of the Datagenerator class\n",
    "trainIterator = datagen.flow(trainX, trainY, batch_size = 64)\n",
    "testIterator = datagen.flow(testX, testY, batch_size = 64)\n",
    "print(\"Batch Sizes: train => %d, test => %d\" % (len(trainIterator), len(testIterator)))\n",
    "\n",
    "# Scaling the pixel values\n",
    "batchX, batchy = next(trainIterator)\n",
    "print(\"Batch size: %s - min => %.3f, max => %.3f\" % (batchX.shape, batchX.min(), batchX.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a89e3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: train => 33.318,  test => 33.791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4262/915441224.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(\"Data Generator Mean: %.3f\" % (datagen.mean))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Generator Mean: 33.318\n",
      "Mean Value of the batch: -1.549\n",
      "Batch: shape => (60000, 28, 28, 1), mean => -0.000020\n"
     ]
    }
   ],
   "source": [
    "# Centering the pixel values of the Dataset\n",
    "\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "\n",
    "print(\"Means: train => %.3f,  test => %.3f\" % (trainX.mean(), testX.mean()))\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center = True)\n",
    "# mean of the training dataset\n",
    "datagen.fit(trainX)\n",
    "print(\"Data Generator Mean: %.3f\" % (datagen.mean))\n",
    "iterator = datagen.flow(trainX, trainY, batch_size = 64)\n",
    "\n",
    "batchX, batchY = next(iterator)\n",
    "\n",
    "print(\"Mean Value of the batch: %.3f\" % batchX.mean())\n",
    "\n",
    "# Effect on entire dataset\n",
    "trainIterator = datagen.flow(trainX, trainY, batch_size = len(trainX), shuffle = False)\n",
    "batchX, batchY = next(trainIterator)\n",
    "print(\"Batch: shape => %s, mean => %f\" % (batchX.shape, batchX.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "636e8649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of train => (mean: 33.318, std: 78.567), test => (mean: 33.791, std: 79.172)\n",
      "Data Generator => (mean: 33.318, std: 78.567)\n",
      "Batch => (shape: (64, 28, 28, 1), mean: -0.014, std: 0.980)\n",
      "Batch => (shape: (64, 28, 28, 1), mean: -0.014, std: 0.987)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4262/2795921329.py:12: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(\"Data Generator => (mean: %.3f, std: %.3f)\" % (datagen.mean, datagen.std))\n"
     ]
    }
   ],
   "source": [
    "# Standardizing the image pixel value\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
    "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
    "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
    "\n",
    "print(\"Statistics of train => (mean: %.3f, std: %.3f), test => (mean: %.3f, std: %.3f)\" % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center = True, featurewise_std_normalization = True)\n",
    "datagen.fit(trainX)\n",
    "print(\"Data Generator => (mean: %.3f, std: %.3f)\" % (datagen.mean, datagen.std))\n",
    "\n",
    "trainIterator = datagen.flow(trainX, trainY, batch_size = 64)\n",
    "batchX, batchY = next(trainIterator)\n",
    "\n",
    "print(\"Batch => (shape: %s, mean: %.3f, std: %.3f)\" % (batchX.shape, batchX.mean(), batchX.std()))\n",
    "\n",
    "wholeTrainIterator = datagen.flow(trainX, trainY, batch_size = 64)\n",
    "batchX, batchY = next(wholeTrainIterator)\n",
    "\n",
    "print(\"Batch => (shape: %s, mean: %.3f, std: %.3f)\" % (batchX.shape, batchX.mean(), batchX.std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
